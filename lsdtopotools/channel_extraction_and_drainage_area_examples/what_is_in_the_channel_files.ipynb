{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LSDtopotools/lsdtt_notebooks/blob/master/lsdtopotools/channel_extraction_and_drainage_area_examples/what_is_in_the_channel_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbdbd983",
      "metadata": {
        "id": "fbdbd983"
      },
      "source": [
        "# What is in the channel files that lsdtopotools produces"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86eeda37",
      "metadata": {
        "id": "86eeda37"
      },
      "source": [
        "Last updated by Simon M Mudd 09/05/2023"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f6a4db",
      "metadata": {
        "id": "06f6a4db"
      },
      "source": [
        "In this notebook we will use an example where you have collected some channel characteristics in the field and we want to know the drainage area of the points. This will include the simplest possible example where all we have is the location of the points. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3144101b",
      "metadata": {
        "id": "3144101b"
      },
      "source": [
        "## Stuff we need to do if you are in colab (not required in the lsdtopotools pytools container)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec1cffe",
      "metadata": {
        "id": "bec1cffe"
      },
      "source": [
        "**If you are in the `docker_lsdtt_pytools` docker container, you do not need to do any of this. \n",
        "The following is for executing this code in the google colab environment only.**\n",
        "\n",
        "If you are in the docker container you can skip to the **Download some data** section. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck6Y73gLvbS8"
      },
      "source": [
        "First we install `lsdviztools`. This will take around a minute. It is important you do this before the `condacolab` step. "
      ],
      "id": "Ck6Y73gLvbS8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj2pwsxkvbS8"
      },
      "outputs": [],
      "source": [
        "!pip install lsdviztools &> /dev/null"
      ],
      "id": "Pj2pwsxkvbS8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq9UDKZrvbS8"
      },
      "source": [
        "Now we need to install lsdtopotools. We do this using something called `mamba`. To get `mamba` we install something called `condacolab`. "
      ],
      "id": "Fq9UDKZrvbS8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea215034"
      },
      "outputs": [],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "id": "ea215034"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXqY5s5T9bqL"
      },
      "source": [
        "Alternatively we can do this by downloading the mamba installer directly, but this frequently leads to various coding conflicts becasue you need to keep the installer URL up to date. `condacolab` does all that for you so you don't need to worry about it. "
      ],
      "id": "DXqY5s5T9bqL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhUkM9Q-9Cje"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#MINICONDA_INSTALLER_SCRIPT=Mambaforge-Linux-x86_64.sh\n",
        "#MINICONDA_PREFIX=/usr/local\n",
        "#wget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh &> /dev/null\n",
        "#chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "#./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX &> /dev/null"
      ],
      "id": "xhUkM9Q-9Cje"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b8c3e17"
      },
      "source": [
        "Now use mamba to install `lsdtopotools`. \n",
        "This step takes a bit over a minute. "
      ],
      "id": "9b8c3e17"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0568f44f"
      },
      "outputs": [],
      "source": [
        "!mamba install -y lsdtopotools &> /dev/null"
      ],
      "id": "0568f44f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNDf3rzQvJca"
      },
      "source": [
        "The next line tests to see if it worked. If you get some output asking for a parameter file then `lsdtopotools` is installed. This notebook was tested on version 0.8."
      ],
      "id": "kNDf3rzQvJca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee7ab7dc"
      },
      "outputs": [],
      "source": [
        "!lsdtt-basic-metrics -v"
      ],
      "id": "ee7ab7dc"
    },
    {
      "cell_type": "markdown",
      "id": "2146b6d9",
      "metadata": {
        "id": "2146b6d9"
      },
      "source": [
        "## First get data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec63078",
      "metadata": {
        "id": "bec63078"
      },
      "source": [
        "Before we do anything, we need to import a few packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb29297c",
      "metadata": {
        "id": "bb29297c"
      },
      "outputs": [],
      "source": [
        "import lsdviztools.lsdbasemaptools as bmt\n",
        "from lsdviztools.lsdplottingtools import lsdmap_gdalio as gio\n",
        "import lsdviztools.lsdmapwrappers as lsdmw"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "035e7024",
      "metadata": {
        "id": "035e7024"
      },
      "source": [
        "Now we need to get some data to download. We are going to download data using the opentopography scraper that is included with `lsdviztools`. You will need to get an opentopography.org account and copy in your API key.\n",
        "\n",
        "You can sign up to an opentopography.org account here: https://portal.opentopography.org/myopentopo "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "167b7c80",
      "metadata": {
        "id": "167b7c80"
      },
      "source": [
        "Before I actually do anything I am going to set up some filenames:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c320b58",
      "metadata": {
        "id": "0c320b58"
      },
      "outputs": [],
      "source": [
        "Dataset_prefix = \"RioAguas\"\n",
        "source_name = \"COP30\"\n",
        "\n",
        "r_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "w_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "\n",
        "DataDirectory = \"./\"\n",
        "Base_file = r_prefix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1fac842",
      "metadata": {
        "id": "f1fac842"
      },
      "source": [
        "Now lets grab the data. If you want to do this yourself for a new area just choose your own lower lect and upper right coordinates of your site"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b05cfd96",
      "metadata": {
        "id": "b05cfd96"
      },
      "outputs": [],
      "source": [
        "# YOU NEED TO PUT YOUR API KEY IN A FILE\n",
        "your_OT_api_key_file = \"my_OT_api_key.txt\"\n",
        "\n",
        "with open(your_OT_api_key_file, 'r') as file:\n",
        "    print(\"I am reading you OT API key from the file \"+your_OT_api_key_file)\n",
        "    api_key = file.read().rstrip()\n",
        "    print(\"Your api key starts with: \"+api_key[0:4])\n",
        "\n",
        "SB_DEM = bmt.ot_scraper(source = source_name,\n",
        "                        lower_left_coordinates = [36.97524478026287, -2.3631792251411805], \n",
        "                        upper_right_coordinates = [37.3200098350942, -1.7962073552766233],\n",
        "                        prefix = Dataset_prefix, \n",
        "                        api_key_file = your_OT_api_key_file)\n",
        "SB_DEM.print_parameters()\n",
        "SB_DEM.download_pythonic()\n",
        "DataDirectory = \"./\"\n",
        "Fname = Dataset_prefix+\"_\"+source_name+\".tif\"\n",
        "gio.convert4lsdtt(DataDirectory,Fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32535c8d",
      "metadata": {
        "id": "32535c8d"
      },
      "source": [
        "## Look at the hillshade"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82861e28",
      "metadata": {
        "id": "82861e28"
      },
      "source": [
        "Right, lets see what this place looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c6d4f1",
      "metadata": {
        "id": "52c6d4f1"
      },
      "outputs": [],
      "source": [
        "lsdtt_parameters = {\"write_hillshade\" : \"true\"}\n",
        "lsdtt_drive = lsdmw.lsdtt_driver(read_prefix = r_prefix,\n",
        "                                 write_prefix= w_prefix,\n",
        "                                 read_path = \"./\",\n",
        "                                 write_path = \"./\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()\n",
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc9cbed6",
      "metadata": {
        "id": "fc9cbed6"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "Base_file = r_prefix\n",
        "DataDirectory = \"./\"\n",
        "this_img = lsdmw.SimpleHillshade(DataDirectory,Base_file,cmap=\"gist_earth\", save_fig=False, size_format=\"geomorphology\",dpi=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e48a872a",
      "metadata": {
        "id": "e48a872a"
      },
      "source": [
        "## Now get a single basin"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1f50f3c",
      "metadata": {
        "id": "a1f50f3c"
      },
      "source": [
        "I add a basin outlet into a pandas dataframe and then copy this to a file. \n",
        "The points below are obtained just by clicking in google maps and copying the resulting lat-long into the below code. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cceedb5a",
      "metadata": {
        "id": "cceedb5a"
      },
      "outputs": [],
      "source": [
        "# Import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "data = [ [37.15674383710805, -1.9049454817508027]]\n",
        "\n",
        "# Create the pandas DataFrame\n",
        "df = pd.DataFrame(data, columns = ['latitude', 'longitude'])\n",
        "\n",
        "df.to_csv(\"basin_outlets.csv\",index=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3359bbb3",
      "metadata": {
        "id": "3359bbb3"
      },
      "source": [
        "We can use the linux `cat` command to make sure the file is what we expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca33f67",
      "metadata": {
        "id": "5ca33f67"
      },
      "outputs": [],
      "source": [
        "!cat basin_outlets.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "034b6ef2",
      "metadata": {
        "id": "034b6ef2"
      },
      "source": [
        "## The different kinds of channel files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d77ff0a4",
      "metadata": {
        "id": "d77ff0a4"
      },
      "source": [
        "You can get channels in a number of ways from `lsdtopotools`.\n",
        "\n",
        "The following are available in `lsdtt-basic-metrics`:\n",
        "    \n",
        "* `print_channels_to_csv:  true` This prints basic information about the channels to a csv file.\n",
        "* `print_chi_data_maps: true` This includes the chi metric and drainage area\n",
        "* `use_extended_channel_data: true` This adds some additional data columns to the above two csv files.\n",
        "\n",
        "You can also control the extent of the channel network with `threshold_contributing_pixels`; a bigger number means a shorter channel network. \n",
        "\n",
        "Lets try these methods out. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6c960b2",
      "metadata": {
        "id": "e6c960b2"
      },
      "source": [
        "### `print_channels_to_csv`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31f6b17b",
      "metadata": {
        "id": "31f6b17b"
      },
      "source": [
        "First we use the `print_channels_to_csv`. This will produce a channel csv with *CN* in the filename:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f4db498",
      "metadata": {
        "id": "8f4db498"
      },
      "outputs": [],
      "source": [
        "## Get the basins and the channel profile\n",
        "lsdtt_parameters = {\"print_channels_to_csv\" : \"true\",\n",
        "                    \"get_basins_from_outlets\" : \"true\",\n",
        "                    \"basin_outlet_csv\" : \"basin_outlets.csv\",\n",
        "                    \"threshold_contributing_pixels\" : \"2000\"}\n",
        "r_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "w_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "lsdtt_drive = lsdmw.lsdtt_driver(command_line_tool = \"lsdtt-chi-mapping\", \n",
        "                                 read_prefix = r_prefix,\n",
        "                                 write_prefix= w_prefix,\n",
        "                                 read_path = \"./\",\n",
        "                                 write_path = \"./\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()\n",
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e58556ae",
      "metadata": {
        "id": "e58556ae"
      },
      "source": [
        "We can look at the data using `pandas`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e95d4b89",
      "metadata": {
        "id": "e95d4b89"
      },
      "outputs": [],
      "source": [
        "# Import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"RioAguas_COP30_UTM_CN.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5af92eb7",
      "metadata": {
        "id": "5af92eb7"
      },
      "source": [
        "So this file includes some flow routing information about the network. It has spatial coordinates (`latitude` and `longitude`) and then various information about the flow routing. Each junction is numbered (this includes sources). The `Junction Index` is the number of the junction upstream. There is also the `receiver_JI` which is the downstream junction to which the channel flows. In addition there are `NI` and `reciever_NI` columns. The `NI` is the node index, which is a number assigned to the pixel (in computational terms it is the index into the flattened array that holds the data) and there is the node index of the receiver pixel (`reciever_NI`). There is also the Strahler stream order (`Stream Order`) of the pixel. \n",
        "\n",
        "**This does not include drainge area because this routine does not check if the basin is complete.**\n",
        "\n",
        "This file is generally only used for plotting the location of the channel. In practise, we really only use the alternative function `get_chi_data_maps`. But we will show you what that does in a second. \n",
        "\n",
        "First though, lets look at what happends when you extend the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf9e29ff",
      "metadata": {
        "id": "cf9e29ff"
      },
      "outputs": [],
      "source": [
        "## Get the basins and the channel profile\n",
        "lsdtt_parameters = {\"print_channels_to_csv\" : \"true\",\n",
        "                    \"get_basins_from_outlets\" : \"true\",\n",
        "                    \"basin_outlet_csv\" : \"basin_outlets.csv\",\n",
        "                    \"threshold_contributing_pixels\" : \"2000\",\n",
        "                    \"use_extended_channel_data\" : \"true\"}\n",
        "r_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "w_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "lsdtt_drive = lsdmw.lsdtt_driver(command_line_tool = \"lsdtt-chi-mapping\", \n",
        "                                 read_prefix = r_prefix,\n",
        "                                 write_prefix= w_prefix,\n",
        "                                 read_path = \"./\",\n",
        "                                 write_path = \"./\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()\n",
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e65cec4d",
      "metadata": {
        "id": "e65cec4d"
      },
      "outputs": [],
      "source": [
        "!ls *.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d8b6f07",
      "metadata": {
        "id": "7d8b6f07"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"RioAguas_COP30_UTM_CN.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ce222a3",
      "metadata": {
        "id": "8ce222a3"
      },
      "source": [
        "So all this realy does is add the elevation to the same file. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Very basic plotting of where the points are using `folium`"
      ],
      "metadata": {
        "id": "H4c0o4HL-YaV"
      },
      "id": "H4c0o4HL-YaV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "`lsdviztools` has a number of plotting routines for making pretty, publication ready figures. But if you just want to see where the data is you can use the package `folium` in conjunction with `pandas`. Note this takes a wee while since there are a lot of points."
      ],
      "metadata": {
        "id": "iVFaSYTe-kVW"
      },
      "id": "iVFaSYTe-kVW"
    },
    {
      "cell_type": "code",
      "source": [
        "# This is for the area threshold points\n",
        "\n",
        "import folium\n",
        "\n",
        "#create a map\n",
        "this_map = folium.Map(prefer_canvas=True, tiles='Stamen Terrain')\n",
        "\n",
        "def plotDot(point):\n",
        "    '''input: series that contains a numeric named latitude and a numeric named longitude\n",
        "    this function creates a CircleMarker and adds it to your this_map'''\n",
        "    folium.CircleMarker(location=[point.latitude, point.longitude],\n",
        "                        radius=2,\n",
        "                        weight=5).add_to(this_map)\n",
        "\n",
        "#use df.apply(,axis=1) to \"iterate\" through every row in your dataframe\n",
        "df.apply(plotDot, axis = 1)\n",
        "\n",
        "\n",
        "#Set the zoom to the maximum possible\n",
        "this_map.fit_bounds(this_map.get_bounds())\n",
        "\n",
        "#Save the map to an HTML file\n",
        "this_map.save('simple_dot_plot.html')\n",
        "\n",
        "this_map"
      ],
      "metadata": {
        "id": "KGjdg92g_VS3"
      },
      "id": "KGjdg92g_VS3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e6f3f8ce",
      "metadata": {
        "id": "e6f3f8ce"
      },
      "source": [
        "### Now for `get_chi_data_maps`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38a9c8a5",
      "metadata": {
        "id": "38a9c8a5"
      },
      "source": [
        "**Firstly, you need to know what the chi coordinate is. If you know this already, skip ahead to the next cell.**\n",
        "\n",
        "To understand it, we start with Morisawa's law that says slope ($S$) is related to drianage area ($A$) via two empirical constants, the concavity index ($\\theta$) and the steepness index ($k_s$):\n",
        "\n",
        "$S = k_s A^{-\\theta}$\n",
        "\n",
        "$S$ is the same as $dz/dx$, the derivative of elevation. $x$ is the flow distance. If we integrate this equation we get:\n",
        "    \n",
        "$z(x) = z(x_b) + \\Big(\\frac{k_s}{{A_0}^{\\theta}}\\Big) \\int_{x_b}^{x} \\Big(\\frac{A_0}{A(x)}\\Big)^{\\theta} dx$\n",
        "\n",
        "where $x_b$ is some arbitrary base level, and $A_0$ is a reference drainage area (this is to ensure the integrand is dimensionless). We almost always set $A_0$ to 1 $m^2$. The integrand seems annoying and messy, but it actually fairly easy to calculate from topographic data (you are just adding drainage area along the length of the channel. You will never need to do this yourself, there is software for calculating the integrand. It also has dimensions length. So we can define a coordinate, $\\chi$:\n",
        "\n",
        "$\\chi = \\int_{x_b}^{x} \\Big(\\frac{A_0}{A(x)}\\Big)^{\\theta} dx$\n",
        "\n",
        "which is just that integrand, but it looks nicer in the equation:\n",
        "\n",
        "$z(x) = z(x_b) + \\Big(\\frac{k_s}{{A_0}^{\\theta}}\\Big) \\chi$\n",
        "\n",
        "Now, have a look at that last equation. This is the equation of a line! \n",
        "\n",
        "From your school maths you might remember a line being written as $y = mx+b$. In this case the gradient of the line is $\\Big(\\frac{k_s}{{A_0}^{\\theta}}\\Big)$.\n",
        "\n",
        "If $A_0$ = 1 $m^2$, then the gradient of the line is the channel steepness index ($k_s$)! This happens to be a very convinient way of extracting the channel steepness, and you can do it with much better accuracy than with slope--area plots. \n",
        "\n",
        "If you want to read more this technique, which is not widely used in geomorphology, you can read this paper:\n",
        "\n",
        "Perron, J.T., Royden, L., 2013. An integral approach to bedrock river profile analysis. Earth Surface Processes and Landforms 38, 570â€“576. https://doi.org/10.1002/esp.3302\n",
        "\n",
        "\n",
        "Note: $\\chi$ is the greek letter chi, which a Greek person would pronounce a bit like the English \"he\". But because most geomorphologsts did not benefit from a classical education they pronounce this letter \"kai\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca46c76f",
      "metadata": {
        "id": "ca46c76f"
      },
      "source": [
        "#### Why `get_chi_data_maps` is more restrictive than `print_channels_to_csv`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e39852c",
      "metadata": {
        "id": "9e39852c"
      },
      "source": [
        "The `get_chi_data_maps` routine is more restrictive then the `print_channels_to_csv` because it enforces complete basins. The reason why is that you must calculate the chi coordinate using the drainage area, and if the drainage area is wrong then the chi coordinate is wrong. \n",
        "\n",
        "**A very common error in `lsdtopotools` is searching for channels in an incomplete basin. The program will reject the basin and you will not extract any channels.** "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fc5c628",
      "metadata": {
        "id": "9fc5c628"
      },
      "source": [
        "Now, lets see what the `print_chi_data_maps` does:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0418227d",
      "metadata": {
        "id": "0418227d"
      },
      "outputs": [],
      "source": [
        "## Get the basins and the channel profile\n",
        "lsdtt_parameters = {\"print_chi_data_maps\" : \"true\",\n",
        "                    \"get_basins_from_outlets\" : \"true\",\n",
        "                    \"basin_outlet_csv\" : \"basin_outlets.csv\",\n",
        "                    \"threshold_contributing_pixels\" : \"2000\"}\n",
        "r_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "w_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "lsdtt_drive = lsdmw.lsdtt_driver(command_line_tool = \"lsdtt-chi-mapping\", \n",
        "                                 read_prefix = r_prefix,\n",
        "                                 write_prefix= w_prefix,\n",
        "                                 read_path = \"./\",\n",
        "                                 write_path = \"./\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()\n",
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a27871da",
      "metadata": {
        "id": "a27871da"
      },
      "source": [
        "This prints a file with `_chi_data_map.csv` in the filename. Lets load it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57e1d690",
      "metadata": {
        "id": "57e1d690"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"RioAguas_COP30_UTM_chi_data_map.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e1c726e",
      "metadata": {
        "id": "7e1c726e"
      },
      "source": [
        "So, what is all this? \n",
        "\n",
        "* `latitude` : the latitude in decimal degrees\n",
        "* `longitude` : the longitude in decimal degrees   \n",
        "* `chi` : the chi coordinate in metres\n",
        "* `elevation` : the elevation in the same units as the DEM (usually metres)\n",
        "* `flow_distance` : the flow distance **from the outlet**.\n",
        "* `drainage_area` : the drainage area of the pixel in m$^2$\n",
        "* `source_key` : each source pixel (or channel head) gets an integer key. Channels are coded by their sources. Longer channels overwrite shorter channels so the main stem channel (here defined as the longest channel) will have all pixels with the same `source_key`. \n",
        "* `basin_key` : Each basin is given a number denoted by the `basin_key`. The longest channel in each basin has the smallest source key in that basin. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc341ab2",
      "metadata": {
        "id": "bc341ab2"
      },
      "source": [
        "Now lets look at the extended version of this csv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "449bc0ad",
      "metadata": {
        "id": "449bc0ad"
      },
      "outputs": [],
      "source": [
        "## Get the basins and the channel profile\n",
        "lsdtt_parameters = {\"print_chi_data_maps\" : \"true\",\n",
        "                    \"get_basins_from_outlets\" : \"true\",\n",
        "                    \"basin_outlet_csv\" : \"basin_outlets.csv\",\n",
        "                    \"threshold_contributing_pixels\" : \"2000\",\n",
        "                    \"use_extended_channel_data\" : \"true\"}\n",
        "r_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "w_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "lsdtt_drive = lsdmw.lsdtt_driver(command_line_tool = \"lsdtt-chi-mapping\", \n",
        "                                 read_prefix = r_prefix,\n",
        "                                 write_prefix= w_prefix,\n",
        "                                 read_path = \"./\",\n",
        "                                 write_path = \"./\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()\n",
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f018569",
      "metadata": {
        "id": "9f018569"
      },
      "outputs": [],
      "source": [
        "!ls *.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "153d802e",
      "metadata": {
        "id": "153d802e"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"RioAguas_COP30_UTM_chi_data_map.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7124b165",
      "metadata": {
        "id": "7124b165"
      },
      "source": [
        "The extended data has many more data elements. These are repeated from the channel_data csv. But perhaps most useful is the `stream_order` data entry. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62422998",
      "metadata": {
        "id": "62422998"
      },
      "source": [
        "## What about channel steepness?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9e8eb35",
      "metadata": {
        "id": "c9e8eb35"
      },
      "source": [
        "If you want to be more complicated, you can use `lsdtt-chi-mapping` to extract the channel steepness. \n",
        "\n",
        "This uses the segmentation algorithm from Mudd et al 2014 (JGR-ES, https://doi.org/10.1002/2013JF002981).\n",
        "\n",
        "To turn it on you need `\"print_segmented_M_chi_map_to_csv\" : \"true\"`\n",
        "\n",
        "Here we set the concavity index (m_over_n) to `0.45`. You actually need to set this for the `get_chi_data_maps` as well but the default is 0.45. \n",
        "\n",
        "**Warning: this is computationally intensive and might take a while.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe5ee3e5",
      "metadata": {
        "id": "fe5ee3e5"
      },
      "outputs": [],
      "source": [
        "lsdtt_parameters = {\"m_over_n\" : \"0.45\",\n",
        "                    \"print_segmented_M_chi_map_to_csv\" : \"true\",\n",
        "                    \"get_basins_from_outlets\" : \"true\",\n",
        "                    \"basin_outlet_csv\" : \"basin_outlets.csv\"}\n",
        "r_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "w_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "lsdtt_drive = lsdmw.lsdtt_driver(command_line_tool = \"lsdtt-chi-mapping\", \n",
        "                                 read_prefix = r_prefix,\n",
        "                                 write_prefix= w_prefix,\n",
        "                                 read_path = \"./\",\n",
        "                                 write_path = \"./\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()\n",
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12d281a6",
      "metadata": {
        "id": "12d281a6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}