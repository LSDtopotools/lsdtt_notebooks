{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting a single channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by Simon M. Mudd, updated 27/03/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKy7_wKyMn9K"
   },
   "source": [
    "## Stuff we need to do if you are in colab (not required in the lsdtopotools pytools container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRWd-_X1vWDf"
   },
   "source": [
    "**If you are in the `docker_lsdtt_pytools` docker container, you do not need to do any of this. \n",
    "The following is for executing this code in the google colab environment only.**\n",
    "\n",
    "If you are in the docker container you can skip to the **Download some data** section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "994da2f2"
   },
   "source": [
    "**If you are in the `docker_lsdtt_pytools` docker container, you do not need to do any of this. \n",
    "The following is for executing this code in the google colab environment only.**\n",
    "\n",
    "If you are in the docker container you can skip to the **First get data** section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ck6Y73gLvbS8"
   },
   "source": [
    "First we install `lsdviztools`. \n",
    "This will take around a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pj2pwsxkvbS8"
   },
   "outputs": [],
   "source": [
    "!pip install lsdviztools &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fq9UDKZrvbS8"
   },
   "source": [
    "Now we need to install lsdtopotools. We do this using something called `mamba`. Note that this version of `mamba` works for python 3.9 (which is what google colab currently uses).\n",
    "\n",
    "This step will take around 20 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhUkM9Q-9Cje"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "MINICONDA_INSTALLER_SCRIPT=Mambaforge-Linux-x86_64.sh\n",
    "MINICONDA_PREFIX=/usr/local\n",
    "wget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh &> /dev/null\n",
    "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
    "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXqY5s5T9bqL"
   },
   "source": [
    "Alternatively we can do this with condacolab, but this broke in March 2023 so will take some time to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ea215034"
   },
   "outputs": [],
   "source": [
    "#!pip install -q condacolab\n",
    "#import condacolab\n",
    "#condacolab.install()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b8c3e17"
   },
   "source": [
    "Now use mamba to install `lsdtopotools`. \n",
    "This step takes a bit over a minute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0568f44f"
   },
   "outputs": [],
   "source": [
    "!mamba install -y lsdtopotools &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNDf3rzQvJca"
   },
   "source": [
    "The next line tests to see if it worked. If you get some output asking for a parameter file then `lsdtopotools` is installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ee7ab7dc"
   },
   "outputs": [],
   "source": [
    "!lsdtt-basic-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the DEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the DEM from opentopography.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsdviztools.lsdbasemaptools as bmt\n",
    "from lsdviztools.lsdplottingtools import lsdmap_gdalio as gio\n",
    "import lsdviztools.lsdmapwrappers as lsdmw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU NEED TO PUT YOUR API KEY IN A FILE\n",
    "your_OT_api_key_file = \"my_OT_api_key.txt\"\n",
    "\n",
    "with open(your_OT_api_key_file, 'r') as file:\n",
    "    print(\"I am reading you OT API key from the file \"+your_OT_api_key_file)\n",
    "    api_key = file.read().rstrip()\n",
    "    print(\"Your api key starts with: \"+api_key[0:4])\n",
    "\n",
    "Dataset_prefix = \"Diablo\"\n",
    "source_name = \"COP30\"\n",
    "\n",
    "SB_DEM = bmt.ot_scraper(source = source_name,\n",
    "                        lower_left_coordinates = [35.1920215020742,-120.90387764783046], \n",
    "                        upper_right_coordinates = [35.296562615076155, -120.73735491824398],\n",
    "                        prefix = Dataset_prefix, \n",
    "                        api_key_file = your_OT_api_key_file)\n",
    "SB_DEM.print_parameters()\n",
    "SB_DEM.download_pythonic()\n",
    "DataDirectory = \"./\"\n",
    "Fname = Dataset_prefix+\"_\"+source_name+\".tif\"\n",
    "gio.convert4lsdtt(DataDirectory,Fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the point from which to extract the channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'id': [0], 'latitude': [35.25298220408284], 'longitude': [-120.77594126937667]}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print this to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"channel_source.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up parameters for an *lsdtopotools* run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsdtt_parameters = {\"write_hillshade\" : \"true\", \n",
    "                    \"extract_single_channel\" : \"true\", \n",
    "                    \"channel_source_fname\" : \"channel_source.csv\", \n",
    "                    \"print_dinf_drainage_area_raster\" : \"true\",\n",
    "                    \"convert_csv_to_geojson\" : \"true\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a driver object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsdtt_drive = lsdmw.lsdtt_driver(read_prefix = \"Diablo_COP30_UTM\",\n",
    "                                 write_prefix= \"Diablo_COP30_UTM\",\n",
    "                                 parameter_dictionary=lsdtt_parameters)\n",
    "lsdtt_drive.print_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run *lsdtopotools*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsdtt_drive.run_lsdtt_command_line_tool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the point data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import cartopy as cp\n",
    "import cartopy.crs as ccrs\n",
    "import rasterio as rio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data using pandas. We then look to see what the column names are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"single_channel_nodes.csv\")\n",
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, there are some stupid spaces in the column names. We can get rid of those with a `strip` command, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns=lambda x: x.strip())\n",
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now convert into a geopandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n",
    "\n",
    "# We have to tell the geopandas data what geographic system we are in by using something called an EPSG code. \n",
    "# All major geographic projection and transformation system have this code. \n",
    "gdf.crs = \"EPSG:4326\" \n",
    "\n",
    "# The head command shows you what is in the file.\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making new data columns: slope and smoothed slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we have flow distance and elevation in this file, but we also want to look at the slope of the channel. To get the slope, we need to calculate the change in elevation over the change in flow distance. The mathematical operation for this is called the gradient (or, if you want to use the notation of derivatives it is `dz/dx`).\n",
    "\n",
    "The python package `numpy` has a built in function for calculating the gradient (`np.gradient`), which we use below to get the slope along the channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = gdf[\"elevation(m)\"]\n",
    "x = gdf[\"flow distance(m)\"]\n",
    "S = np.gradient(np.asarray(z),np.asarray(x))\n",
    "gdf[\"slope\"] = S\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "# Now make channel profile plots\n",
    "z = gdf[\"elevation(m)\"]\n",
    "x_locs = gdf[\"flow distance(m)\"]\n",
    "S = gdf.slope\n",
    "\n",
    "# Create two subplots and unpack the output array immediately\n",
    "plt.clf()\n",
    "f, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.scatter(x_locs, z,s = 0.2)\n",
    "ax2.scatter(x_locs, S,s = 1)\n",
    "\n",
    "\n",
    "ax1.set_xlabel(\"Distance from outlet ($m$)\")\n",
    "ax1.set_ylabel(\"elevation (m)\")\n",
    "\n",
    "ax2.set_xlabel(\"Distance from outlet ($m$)\")\n",
    "ax2.set_ylabel(\"Slope (m/m)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This slope (bottom figure) is very noisy. One way to deal with this is to smooth the data. We can smooth the data by running a mobing window over it and doing some averaging inside the window. \n",
    "\n",
    "Python has lots of tools for this. In this case I use a `rolling` window and I have picked various settings. You don't need to worry about this too much, the only number that you might wanty to play with is the first number after `rolling` which is the number of datapoints in the window. The bigger this number, the more smoothed the data becomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['slope_rolling'] = gdf.slope.rolling(40,win_type='hamming').mean()\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot will show the slope and the rolling slope, so you can see how the rolling window smooths the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "# Now make channel profile plots\n",
    "# To get a single data column from a pandas dataframe (in this case called gdf_b2) you just put\n",
    "# a full stop and then the name of the column\n",
    "# If your column has spaces or funny characters in the name you need to use the square brackets like this:\n",
    "# z = gdf_b2[\"elevation\"]\n",
    "# Which is an alternative way of isolating data\n",
    "z = gdf[\"elevation(m)\"]\n",
    "x_locs = gdf[\"flow distance(m)\"]\n",
    "S = gdf.slope\n",
    "SR = gdf.slope_rolling\n",
    "\n",
    "# Create two subplots and unpack the output array immediately\n",
    "plt.clf()\n",
    "f, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.scatter(x_locs, S,s = 1)\n",
    "ax2.scatter(x_locs, SR,s = 1)\n",
    "\n",
    "\n",
    "ax1.set_xlabel(\"Distance from outlet ($m$)\")\n",
    "ax1.set_ylabel(\"Slope (m/m)\")\n",
    "\n",
    "ax2.set_xlabel(\"Distance from outlet ($m$)\")\n",
    "ax2.set_ylabel(\"Rolling Slope (m/m)\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the gradient and where the high gradient channels are along the channel profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the rolling slope allows us to see some spikes in the gradient. Can we see this in the right places along the channel profile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "# Now make channel profile plots\n",
    "z = gdf[\"elevation(m)\"]\n",
    "x_locs = gdf[\"flow distance(m)\"]\n",
    "S = gdf.slope\n",
    "SR = gdf.slope_rolling\n",
    "\n",
    "# Create two subplots and unpack the output array immediately\n",
    "plt.clf()\n",
    "f, (ax1) = plt.subplots(1, 1)\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "# Make the scatter plots\n",
    "ax1.scatter(x_locs, z,s = 1, label='Longitudinal profile')\n",
    "ax2.scatter(x_locs, SR,s = 1,c=\"r\", label='Channel slope')\n",
    "\n",
    "# Some code to make sure the legend renders on the same axis\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc=0)\n",
    "\n",
    "\n",
    "ax1.set_xlabel(\"Distance from outlet ($m$)\")\n",
    "ax1.set_ylabel(\"Elevation (m)\")\n",
    "\n",
    "ax2.set_xlabel(\"Distance from outlet ($m$)\")\n",
    "ax2.set_ylabel(\"Rolling Slope (m/m)\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the channel gradients to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am afraid it is a little bit complicated to save the smoothed channel gradients to csv. \n",
    "\n",
    "Why? Becasue there are jumps in the flow distance at the tributary junctions. \n",
    "\n",
    "So to get the channel gradients we need to loop through each source key and get the gradients one by one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now print to csv\n",
    "gdf_b1.to_csv(\"diablo_channel_with_gradient.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
