{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LSDtopotools/lsdtt_notebooks/blob/master/lsdtopotools/channel_extraction_and_drainage_area_examples/extract_single_channel_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRk3BWJ5ACwJ"
      },
      "source": [
        "# Extracting a single channel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This extracts a single channel where you give it the channel source and it follows the channel downstream to the edge of the DEM."
      ],
      "metadata": {
        "id": "u9ApHf4nAMCh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpmkiSCMACwO"
      },
      "source": [
        "Written by Simon M. Mudd, updated 08/05/2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKy7_wKyMn9K"
      },
      "source": [
        "## Stuff we need to do if you are in colab (not required in the lsdtopotools pytools container)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWd-_X1vWDf"
      },
      "source": [
        "**If you are in the `docker_lsdtt_pytools` docker container, you do not need to do any of this. \n",
        "The following is for executing this code in the google colab environment only.**\n",
        "\n",
        "If you are in the docker container you can skip to the **Download some data** section. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck6Y73gLvbS8"
      },
      "source": [
        "First we install `lsdviztools`. This will take around a minute. It is important you do this before the `condacolab` step. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj2pwsxkvbS8"
      },
      "outputs": [],
      "source": [
        "!pip install lsdviztools &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq9UDKZrvbS8"
      },
      "source": [
        "Now we need to install lsdtopotools. We do this using something called `mamba`. To get `mamba` we install something called `condacolab`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea215034"
      },
      "outputs": [],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXqY5s5T9bqL"
      },
      "source": [
        "Alternatively we can do this by downloading the mamba installer directly, but this frequently leads to various coding conflicts becasue you need to keep the installer URL up to date. `condacolab` does all that for you so you don't need to worry about it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhUkM9Q-9Cje"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#MINICONDA_INSTALLER_SCRIPT=Mambaforge-Linux-x86_64.sh\n",
        "#MINICONDA_PREFIX=/usr/local\n",
        "#wget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh &> /dev/null\n",
        "#chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "#./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b8c3e17"
      },
      "source": [
        "Now use mamba to install `lsdtopotools`. \n",
        "This step takes a bit over a minute. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0568f44f"
      },
      "outputs": [],
      "source": [
        "!mamba install -y lsdtopotools &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNDf3rzQvJca"
      },
      "source": [
        "The next line tests to see if it worked. If you get some output asking for a parameter file then `lsdtopotools` is installed. This notebook was tested on version 0.8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee7ab7dc"
      },
      "outputs": [],
      "source": [
        "!lsdtt-basic-metrics -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPUhL6PDACwZ"
      },
      "source": [
        "## Get the DEM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtGVVS4vACwZ"
      },
      "source": [
        "Grab the DEM from opentopography.org"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPWaKogbACwZ"
      },
      "outputs": [],
      "source": [
        "import lsdviztools.lsdbasemaptools as bmt\n",
        "from lsdviztools.lsdplottingtools import lsdmap_gdalio as gio\n",
        "import lsdviztools.lsdmapwrappers as lsdmw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPLyAyeaACwa"
      },
      "outputs": [],
      "source": [
        "# YOU NEED TO PUT YOUR API KEY IN A FILE\n",
        "your_OT_api_key_file = \"my_OT_api_key.txt\"\n",
        "\n",
        "with open(your_OT_api_key_file, 'r') as file:\n",
        "    print(\"I am reading you OT API key from the file \"+your_OT_api_key_file)\n",
        "    api_key = file.read().rstrip()\n",
        "    print(\"Your api key starts with: \"+api_key[0:4])\n",
        "\n",
        "Dataset_prefix = \"Diablo\"\n",
        "source_name = \"COP30\"\n",
        "\n",
        "SB_DEM = bmt.ot_scraper(source = source_name,\n",
        "                        lower_left_coordinates = [35.1920215020742,-120.90387764783046], \n",
        "                        upper_right_coordinates = [35.296562615076155, -120.73735491824398],\n",
        "                        prefix = Dataset_prefix, \n",
        "                        api_key_file = your_OT_api_key_file)\n",
        "SB_DEM.print_parameters()\n",
        "SB_DEM.download_pythonic()\n",
        "DataDirectory = \"./\"\n",
        "Fname = Dataset_prefix+\"_\"+source_name+\".tif\"\n",
        "gio.convert4lsdtt(DataDirectory,Fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcdPIsobACwa"
      },
      "source": [
        "# Get the point from which to extract the channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_RlpERkACwb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BziOJ2WcACwb"
      },
      "outputs": [],
      "source": [
        "d = {'id': [0], 'latitude': [35.25298220408284], 'longitude': [-120.77594126937667]}\n",
        "df = pd.DataFrame(data=d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD0ZOr3cACwc"
      },
      "source": [
        "Print this to a csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGJtwTdAACwc"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"channel_source.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wLN1_BbACwc"
      },
      "source": [
        "# Set up parameters for an *lsdtopotools* run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvP6FZX-ACwc"
      },
      "outputs": [],
      "source": [
        "lsdtt_parameters = {\"write_hillshade\" : \"true\", \n",
        "                    \"extract_single_channel\" : \"true\", \n",
        "                    \"channel_source_fname\" : \"channel_source.csv\", \n",
        "                    \"print_dinf_drainage_area_raster\" : \"true\",\n",
        "                    \"convert_csv_to_geojson\" : \"true\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q39kzF0KACwd"
      },
      "source": [
        "Create a driver object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sKGfFOXACwd"
      },
      "outputs": [],
      "source": [
        "lsdtt_drive = lsdmw.lsdtt_driver(read_prefix = \"Diablo_COP30_UTM\",\n",
        "                                 write_prefix= \"Diablo_COP30_UTM\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E2Fn-99ACwd"
      },
      "source": [
        "Run *lsdtopotools*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfh3mUM_ACwd"
      },
      "outputs": [],
      "source": [
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akkVuBsmACwd"
      },
      "source": [
        "## Look at the point data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkJIva6xACwe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import cartopy as cp\n",
        "import cartopy.crs as ccrs\n",
        "import rasterio as rio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wULgMCmACwe"
      },
      "source": [
        "Let's load the data using pandas. We then look to see what the column names are. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9yOGHiGACwe"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"single_channel_nodes.csv\")\n",
        "list(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD9xVl8EACwe"
      },
      "source": [
        "Oh, there are some stupid spaces in the column names. We can get rid of those with a `strip` command, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHlgu9ciACwe"
      },
      "outputs": [],
      "source": [
        "df = df.rename(columns=lambda x: x.strip())\n",
        "list(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QcsZh76ACwf"
      },
      "source": [
        "We can now convert into a geopandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7MhsbtmACwf"
      },
      "outputs": [],
      "source": [
        "gdf = gpd.GeoDataFrame(\n",
        "    df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n",
        "\n",
        "# We have to tell the geopandas data what geographic system we are in by using something called an EPSG code. \n",
        "# All major geographic projection and transformation system have this code. \n",
        "gdf.crs = \"EPSG:4326\" \n",
        "\n",
        "# The head command shows you what is in the file.\n",
        "gdf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe5Gc4ldACwf"
      },
      "source": [
        "## Making new data columns: slope and smoothed slope"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Uhg_wZPACwf"
      },
      "source": [
        "Okay, we have flow distance and elevation in this file, but we also want to look at the slope of the channel. To get the slope, we need to calculate the change in elevation over the change in flow distance. The mathematical operation for this is called the gradient (or, if you want to use the notation of derivatives it is `dz/dx`).\n",
        "\n",
        "The python package `numpy` has a built in function for calculating the gradient (`np.gradient`), which we use below to get the slope along the channel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--rVRVWOACwg"
      },
      "outputs": [],
      "source": [
        "z = gdf[\"elevation(m)\"]\n",
        "x = gdf[\"flow distance(m)\"]\n",
        "S = np.gradient(np.asarray(z),np.asarray(x))\n",
        "gdf[\"slope\"] = S\n",
        "gdf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOA0HFVwACwg"
      },
      "source": [
        "Now lets plot the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8msNVhceACwg"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [10, 10]\n",
        "\n",
        "# Now make channel profile plots\n",
        "z = gdf[\"elevation(m)\"]\n",
        "x_locs = gdf[\"flow distance(m)\"]\n",
        "S = gdf.slope\n",
        "\n",
        "# Create two subplots and unpack the output array immediately\n",
        "plt.clf()\n",
        "f, (ax1, ax2) = plt.subplots(2, 1)\n",
        "ax1.scatter(x_locs, z,s = 0.2)\n",
        "ax2.scatter(x_locs, S,s = 1)\n",
        "\n",
        "\n",
        "ax1.set_xlabel(\"Distance from outlet ($m$)\")\n",
        "ax1.set_ylabel(\"elevation (m)\")\n",
        "\n",
        "ax2.set_xlabel(\"Distance from outlet ($m$)\")\n",
        "ax2.set_ylabel(\"Slope (m/m)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxYyuZ1CACwg"
      },
      "source": [
        "This slope (bottom figure) is very noisy. One way to deal with this is to smooth the data. We can smooth the data by running a mobing window over it and doing some averaging inside the window. \n",
        "\n",
        "Python has lots of tools for this. In this case I use a `rolling` window and I have picked various settings. You don't need to worry about this too much, the only number that you might wanty to play with is the first number after `rolling` which is the number of datapoints in the window. The bigger this number, the more smoothed the data becomes. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz4OdtyFACwg"
      },
      "outputs": [],
      "source": [
        "gdf['slope_rolling'] = gdf.slope.rolling(40,win_type='hamming').mean()\n",
        "gdf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojtIS2U-ACwh"
      },
      "source": [
        "This plot will show the slope and the rolling slope, so you can see how the rolling window smooths the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsH5q4-oACwh"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [10, 10]\n",
        "\n",
        "# Now make channel profile plots\n",
        "# To get a single data column from a pandas dataframe (in this case called gdf_b2) you just put\n",
        "# a full stop and then the name of the column\n",
        "# If your column has spaces or funny characters in the name you need to use the square brackets like this:\n",
        "# z = gdf_b2[\"elevation\"]\n",
        "# Which is an alternative way of isolating data\n",
        "z = gdf[\"elevation(m)\"]\n",
        "x_locs = gdf[\"flow distance(m)\"]\n",
        "S = gdf.slope\n",
        "SR = gdf.slope_rolling\n",
        "\n",
        "# Create two subplots and unpack the output array immediately\n",
        "plt.clf()\n",
        "f, (ax1, ax2) = plt.subplots(2, 1)\n",
        "ax1.scatter(x_locs, S,s = 1)\n",
        "ax2.scatter(x_locs, SR,s = 1)\n",
        "\n",
        "\n",
        "ax1.set_xlabel(\"Distance from outlet ($m$)\")\n",
        "ax1.set_ylabel(\"Slope (m/m)\")\n",
        "\n",
        "ax2.set_xlabel(\"Distance from outlet ($m$)\")\n",
        "ax2.set_ylabel(\"Rolling Slope (m/m)\")\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOQLyT6tACwh"
      },
      "source": [
        "## Looking at the gradient and where the high gradient channels are along the channel profile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yCpKi_1ACwh"
      },
      "source": [
        "Okay, the rolling slope allows us to see some spikes in the gradient. Can we see this in the right places along the channel profile?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZS2vDmQACwi"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "# Now make channel profile plots\n",
        "z = gdf[\"elevation(m)\"]\n",
        "x_locs = gdf[\"flow distance(m)\"]\n",
        "S = gdf.slope\n",
        "SR = gdf.slope_rolling\n",
        "\n",
        "# Create two subplots and unpack the output array immediately\n",
        "plt.clf()\n",
        "f, (ax1) = plt.subplots(1, 1)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "# Make the scatter plots\n",
        "ax1.scatter(x_locs, z,s = 1, label='Longitudinal profile')\n",
        "ax2.scatter(x_locs, SR,s = 1,c=\"r\", label='Channel slope')\n",
        "\n",
        "# Some code to make sure the legend renders on the same axis\n",
        "lines, labels = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax2.legend(lines + lines2, labels + labels2, loc=0)\n",
        "\n",
        "\n",
        "ax1.set_xlabel(\"Distance from outlet ($m$)\")\n",
        "ax1.set_ylabel(\"Elevation (m)\")\n",
        "\n",
        "ax2.set_xlabel(\"Distance from outlet ($m$)\")\n",
        "ax2.set_ylabel(\"Rolling Slope (m/m)\")\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR8sW6eGACwi"
      },
      "source": [
        "## Saving the channel gradients to csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J-dRNqGACwi"
      },
      "source": [
        "I am afraid it is a little bit complicated to save the smoothed channel gradients to csv. \n",
        "\n",
        "Why? Becasue there are jumps in the flow distance at the tributary junctions. \n",
        "\n",
        "So to get the channel gradients we need to loop through each source key and get the gradients one by one. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXHd91XBACwi"
      },
      "outputs": [],
      "source": [
        "# Now print to csv\n",
        "gdf_b1.to_csv(\"diablo_channel_with_gradient.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z7n4ArmACwi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}