{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LSDtopotools/lsdtt_notebooks/blob/master/lsdtopotools/cosmogenic_examples/CRN_erosion_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e93eb819",
      "metadata": {
        "id": "e93eb819"
      },
      "source": [
        "# Template for erosion rate calculations based on 10Be concentrations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6ab5597",
      "metadata": {
        "id": "d6ab5597"
      },
      "source": [
        "Last updated by Simon M. Mudd on 03/02/2023"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ce30997",
      "metadata": {
        "id": "9ce30997"
      },
      "source": [
        "This is a template you can use to calculate erosion rates from 10Be concentrations in detrital stream sediments. It uses CAIRN (https://doi.org/10.5194/esurf-4-655-2016) to make these computations. \n",
        "\n",
        "You will need to enter your own data but otherwise just follow the template and you will soon be computing erosion rates. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b27be8f",
      "metadata": {
        "id": "4b27be8f"
      },
      "source": [
        "## If you are on colab"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "994da2f2",
      "metadata": {
        "id": "994da2f2"
      },
      "source": [
        "**If you are in the `docker_lsdtt_pytools` docker container, you do not need to do any of this. \n",
        "The following is for executing this code in the google colab environment only.**\n",
        "\n",
        "If you are in the docker container you can skip to the **First get data** section. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UVnt20YbQgIN",
      "metadata": {
        "id": "UVnt20YbQgIN"
      },
      "source": [
        "First we install `lsdviztools`. \n",
        "\n",
        "Note that if we install `condacolab` first the `lsdviztools` installation fails. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Se7ToFPsPBp6",
      "metadata": {
        "id": "Se7ToFPsPBp6"
      },
      "outputs": [],
      "source": [
        "!pip install lsdviztools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LNOjp2ocMzFE",
      "metadata": {
        "id": "LNOjp2ocMzFE"
      },
      "source": [
        "Now we need to install lsdtopotools. We do this using something called `condacolab`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea215034",
      "metadata": {
        "id": "ea215034"
      },
      "outputs": [],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b8c3e17",
      "metadata": {
        "id": "9b8c3e17"
      },
      "source": [
        "Now use mamba to install `lsdtopotools`. This will install the command line tools. This step takes a bit over a minute. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0568f44f",
      "metadata": {
        "id": "0568f44f"
      },
      "outputs": [],
      "source": [
        "!mamba install lsdtopotools &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee7ab7dc",
      "metadata": {
        "id": "ee7ab7dc"
      },
      "outputs": [],
      "source": [
        "!lsdtt-basic-metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d95763d",
      "metadata": {
        "id": "5d95763d"
      },
      "source": [
        "## Get the climate data required for the analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b3eb5e",
      "metadata": {
        "id": "c3b3eb5e"
      },
      "source": [
        "We need to get some data that is used to compute pressure for our samples. This affects the 10Be production rate. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a00b369",
      "metadata": {
        "id": "3a00b369"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/CRNData/NCEP2.bin\", \"NCEP2.bin\")\n",
        "urllib.request.urlretrieve(\"https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/CRNData/NCEP_hgt.bin\", \"NCEP_hgt.bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03bec632",
      "metadata": {
        "id": "03bec632"
      },
      "source": [
        "## Getting topographic data of your study area from OpenTopography.org"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "910f56f9",
      "metadata": {
        "id": "910f56f9"
      },
      "source": [
        "OpenTopograhy (https://www.opentopography.org/) is a great place to download topographic data. \n",
        "\n",
        "It has vast quantities of lidar data that you can download from the site. In addition there is an API for downloading global datasets (at a range of resolutions). \n",
        "\n",
        "`lsdviztools` has a script that can download this global data and convert it to the file format and coordinate reference system (CRS) you need for analysis in `lsdtopotools`. \n",
        "\n",
        "**To do this you need to have a user account at OpenTopography.** You can sign up to an opentopography.org account here: https://portal.opentopography.org/myopentopo \n",
        "\n",
        "Once you have done that, you should get your API key and paste it into a text file somewhere safe (if any digital security experts want to explain how to better do this I am all ears). You will need to point to that file when calling the `lsdviztools` opentopography scraper. \n",
        "\n",
        "If you are working in *colab* then you should upload the file into your working directory. \n",
        "\n",
        "* You need to add the lower left and upper right hand coordinates, in lat-long, of your study area. \n",
        "* You can do this by right clicking and copying coordinates on google maps\n",
        "* Also set a data prefix name\n",
        "* And decide on the data type: options here https://portal.opentopography.org/apidocs/#/Public/getGlobalDem, we use COP30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed430f5a",
      "metadata": {
        "id": "ed430f5a"
      },
      "outputs": [],
      "source": [
        "lower_left_coords = [23.020977925808698, -110.07075635034748] \n",
        "upper_right_coords = [23.339739844695995, -109.79747144601774]\n",
        "Dataset_name = \"baja\"\n",
        "source_name = \"COP30\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69dca70d",
      "metadata": {
        "id": "69dca70d"
      },
      "source": [
        "If we are not on colab I need to ensure we have the correct version of `lsdviztools`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e09b4c1",
      "metadata": {
        "id": "3e09b4c1"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade lsdviztools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4b47b2b",
      "metadata": {
        "id": "c4b47b2b"
      },
      "outputs": [],
      "source": [
        "import lsdviztools.lsdbasemaptools as bmt\n",
        "from lsdviztools.lsdplottingtools import lsdmap_gdalio as gio\n",
        "\n",
        "# YOU NEED TO PUT YOUR API KEY IN A FILE\n",
        "your_OT_api_key_file = \"my_OT_api_key.txt\"\n",
        "\n",
        "with open(your_OT_api_key_file, 'r') as file:\n",
        "    print(\"I am reading you OT API key from the file \"+your_OT_api_key_file)\n",
        "    api_key = file.read().rstrip()\n",
        "    print(\"Your api key starts with: \"+api_key[0:4])\n",
        "\n",
        "study_DEM = bmt.ot_scraper(source = source_name,\n",
        "                        lower_left_coordinates = lower_left_coords, \n",
        "                        upper_right_coordinates = upper_right_coords,\n",
        "                        prefix = Dataset_name, \n",
        "                        api_key_file = your_OT_api_key_file)\n",
        "study_DEM.print_parameters()\n",
        "study_DEM.download_pythonic()\n",
        "DataDirectory = \"./\"\n",
        "Fname = Dataset_name+\"_\"+source_name+\".tif\"\n",
        "gio.convert4lsdtt(DataDirectory,Fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32535c8d",
      "metadata": {
        "id": "32535c8d"
      },
      "source": [
        "## Make sure the data is in the correct place"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82861e28",
      "metadata": {
        "id": "82861e28"
      },
      "source": [
        "Right, lets see what this place looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4429922",
      "metadata": {
        "id": "a4429922"
      },
      "outputs": [],
      "source": [
        "import lsdviztools.lsdmapwrappers as lsdmw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c6d4f1",
      "metadata": {
        "id": "52c6d4f1"
      },
      "outputs": [],
      "source": [
        "lsdtt_parameters = {\"write_hillshade\" : \"true\"}\n",
        "r_prefix = Dataset_name+\"_\"+source_name +\"_UTM\"\n",
        "w_prefix = Dataset_name+\"_\"+source_name +\"_UTM\"\n",
        "lsdtt_drive = lsdmw.lsdtt_driver(read_prefix = r_prefix,\n",
        "                                 write_prefix= w_prefix,\n",
        "                                 read_path = \"./\",\n",
        "                                 write_path = \"./\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()\n",
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbdbb352",
      "metadata": {
        "id": "cbdbb352"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "Base_file = r_prefix\n",
        "DataDirectory = \"./\"\n",
        "this_img = lsdmw.SimpleHillshade(DataDirectory,Base_file,cmap=\"gist_earth\", save_fig=False, size_format=\"geomorphology\",dpi=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be6becef",
      "metadata": {
        "id": "be6becef"
      },
      "source": [
        "## Now for some parameter files for the analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dd0945f",
      "metadata": {
        "id": "3dd0945f"
      },
      "source": [
        "We need a few data files to run the analysis. You probably don't need to change any of these unless you are an advanced user. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d011404e",
      "metadata": {
        "id": "d011404e"
      },
      "outputs": [],
      "source": [
        "CRN_param_fname = \"./\"+Dataset_name+\"_\"+source_name +\"_UTM.CRNParam\"\n",
        "CRN_rasters_fname = \"./\"+Dataset_name+\"_\"+source_name +\"_UTM_CRNRasters.csv\"\n",
        "\n",
        "with open(CRN_param_fname, 'w', encoding=\"utf-8\") as f:\n",
        "    f.write('min_slope: 0.0001\\n')\n",
        "    f.write('source_threshold: 12\\n')\n",
        "    f.write('search_radius_nodes: 4\\n')\n",
        "    f.write('threshold_stream_order: 2\\n')\n",
        "    f.write('theta_step: 30\\n')\n",
        "    f.write('phi_step: 30\\n')\n",
        "    f.write('Muon_scaling: BraucherBorchers\\n')\n",
        "\n",
        "with open(CRN_rasters_fname, 'w', encoding=\"utf-8\") as f:\n",
        "    f.write(\"./\"+Dataset_name+\"_\"+source_name +\"_UTM\")\n",
        "    f.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd993f99",
      "metadata": {
        "id": "cd993f99"
      },
      "source": [
        "## Now your cosmogenic data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1e637a6",
      "metadata": {
        "id": "a1e637a6"
      },
      "source": [
        "Now you need to add in your cosmogenic data. \n",
        "\n",
        "This has a very specific format.\n",
        "\n",
        "It needs to be in a csv file, with headers:\n",
        "`sample_name,sample_latitude,sample_longitude,nuclide,concentration,AMS_uncertainty,standardisation`\n",
        "\n",
        "* The `sample_name` can be anything\n",
        "* `sample_latitude` and `sample_longitude` should be obvious. \n",
        "* `nuclide` needs to be `Be10` (exactly that, `10Be` will not work)\n",
        "* `standardisation` needs to come from a list, if it is not recognised it will default to the `07KNSTD`\n",
        "\n",
        "**You can have this file called anything, but I will copy and rename it here in the template**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4465339a",
      "metadata": {
        "id": "4465339a"
      },
      "outputs": [],
      "source": [
        "my_CRN_data_filename = \"ENTER_YOUR_FILENAME_HERE.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b336c6a0",
      "metadata": {
        "id": "b336c6a0"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "new_filename = \"./\"+Dataset_name+\"_\"+source_name +\"_UTM_CRNData.csv\"\n",
        "subprocess.run([\"cp\", my_CRN_data_filename, new_filename])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb81204f",
      "metadata": {
        "id": "fb81204f"
      },
      "source": [
        "### We can check where the points are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "928d6924",
      "metadata": {
        "id": "928d6924"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "CRNData_df = pd.read_csv(new_filename)\n",
        "CRNData_df[\"latitude\"] =  CRNData_df[\" sample_latitude\"]\n",
        "CRNData_df[\"longitude\"] =  CRNData_df[\" sample_longitude\"]\n",
        "CRNData_df.to_csv(\"temp_CRNData_latlong.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d4beb4a",
      "metadata": {
        "id": "7d4beb4a"
      },
      "outputs": [],
      "source": [
        "### Plot points the hillshade\n",
        "import lsdviztools.lsdmapwrappers as lsdmw\n",
        "%matplotlib inline\n",
        "Base_file = Dataset_name+\"_\"+source_name +\"_UTM\"\n",
        "DataDirectory = \"./\"\n",
        "this_img = lsdmw.PrintPointsOverHillshade(DataDirectory,Base_file, column_for_plotting = \"concentration\", \n",
        "                                          points_fname = \"temp_CRNData_latlong.csv\", \n",
        "                                          scale_points = False, manual_size =50,\n",
        "                                          cmap=\"jet\", save_fig=False, size_format=\"geomorphology\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e8fef7a",
      "metadata": {
        "id": "5e8fef7a"
      },
      "source": [
        "## Check the cosmo data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f38a286e",
      "metadata": {
        "id": "f38a286e"
      },
      "source": [
        "In this next step we check to see if the cosmo data is in the right place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aba17303",
      "metadata": {
        "id": "aba17303"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT all the parameter values must be passed as strings. \n",
        "# So even if the parameter is a number it always needs to be in quotations\n",
        "lsdtt_parameters = {\"cosmo_parameter_prefix\" : Dataset_name+\"_\"+source_name +\"_UTM\",\n",
        "                    \"check_cosmo_basins\" : \"true\"}\n",
        "r_prefix = Dataset_name+\"_\"+source_name +\"_UTM\"\n",
        "w_prefix = Dataset_name+\"_\"+source_name +\"_UTM\"\n",
        "lsdtt_drive = lsdmw.lsdtt_driver(command_line_tool = \"lsdtt-cosmo-tool\",\n",
        "                                 read_prefix = r_prefix,\n",
        "                                 write_prefix= w_prefix,\n",
        "                                 read_path = \"./\",\n",
        "                                 write_path = \"./\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()\n",
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86d9b273",
      "metadata": {
        "id": "86d9b273"
      },
      "source": [
        "This gets the basins, which we can plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96f88044",
      "metadata": {
        "id": "96f88044"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "DataDirectory = \"./\"\n",
        "Base_file = Dataset_name+\"_\"+source_name +\"_UTM\"\n",
        "basins_img = lsdmw.PrintBasins_Complex(DataDirectory,Base_file,cmap=\"gist_earth\", \n",
        "                             size_format=\"geomorphology\",dpi=600, save_fig = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa701a6",
      "metadata": {
        "id": "4aa701a6"
      },
      "outputs": [],
      "source": [
        "print(basins_img)\n",
        "from IPython.display import display, Image\n",
        "display(Image(filename=basins_img, width=800))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b4ceaf8",
      "metadata": {
        "id": "1b4ceaf8"
      },
      "source": [
        "## Now lets get the erosion rates!!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d054a6ce",
      "metadata": {
        "id": "d054a6ce"
      },
      "source": [
        "Now we are going to extract the erosion rates. This takes a little while since it automatically calculates topographic shielding, which is the most computationally expensive step. \n",
        "\n",
        "There is a quite good argument that topographic shielding is not required, but I've not implemented an automatic skip of this step yet. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfa08c48",
      "metadata": {
        "id": "dfa08c48"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT all the parameter values must be passed as strings. \n",
        "# So even if the parameter is a number it always needs to be in quotations\n",
        "lsdtt_parameters = {\"print_production_raster\" : \"true\",\n",
        "                    \"cosmo_parameter_prefix\" : Dataset_name+\"_\"+source_name +\"_UTM\",\n",
        "                    \"calculate_erosion_rates\" : \"true\",\n",
        "                   }\n",
        "r_prefix = Dataset_name+\"_\"+source_name +\"_UTM\"\n",
        "w_prefix = Dataset_name+\"_\"+source_name +\"_UTM\"\n",
        "lsdtt_drive = lsdmw.lsdtt_driver(command_line_tool = \"lsdtt-cosmo-tool\",\n",
        "                                 read_prefix = r_prefix,\n",
        "                                 write_prefix= w_prefix,\n",
        "                                 read_path = \"./\",\n",
        "                                 write_path = \"./\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()\n",
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26175336",
      "metadata": {
        "id": "26175336"
      },
      "source": [
        "## Now lets see what the samples say!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3277f74",
      "metadata": {
        "id": "a3277f74"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_name = \"./\"+Dataset_name+\"_\"+source_name +\"_UTM_CRNResults.csv\"\n",
        "CRNResults_df = pd.read_csv(data_name,skiprows=3)\n",
        "print(CRNResults_df[['sample_name', 'erate_mmperkyr_rho2650']])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}