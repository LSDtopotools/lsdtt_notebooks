{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3354e4b",
   "metadata": {},
   "source": [
    "# Erosion rates from CRN concentrations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e172342",
   "metadata": {},
   "source": [
    "Notebook last updated by Simon M Mudd 19/12/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536f50f",
   "metadata": {},
   "source": [
    "In this example we will use CAIRN (https://doi.org/10.5194/esurf-4-655-2016) to calculate erosion rates based on the concentration of $^{10}$Be in detrital sediments.\n",
    "\n",
    "This method requires some input files that we will get from example data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b27be8f",
   "metadata": {
    "id": "4b27be8f"
   },
   "source": [
    "## If you are on colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec1cffe",
   "metadata": {
    "id": "bec1cffe"
   },
   "source": [
    "**If you are in the `docker_lsdtt_pytools` docker container, you do not need to do any of this. \n",
    "The following is for executing this code in the google colab environment only.**\n",
    "\n",
    "If you are in the docker container you can skip to the **Download some data** section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea2011",
   "metadata": {},
   "source": [
    "First we install `lsdtopotools`. The first line downloads the package and the second installs it. The `/dev/null` stuff is just to stop the notebook printing a bunch of text to screen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://pkgs.geos.ed.ac.uk/geos-jammy/pool/world/l/lsdtopotools2/lsdtopotools2_0.9-1geos~22.04.1_amd64.deb  &> /dev/null\n",
    "!apt install ./lsdtopotools2_0.9-1geos~22.04.1_amd64.deb  &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c95d9",
   "metadata": {},
   "source": [
    "The next line tests to see if it worked. If you get some output asking for a parameter file then `lsdtopotools` is installed. This notebook was tested on version 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb87fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lsdtt-basic-metrics -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11191e7d",
   "metadata": {},
   "source": [
    "Now we install `lsdviztools`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b19ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lsdviztools  &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994da2f2",
   "metadata": {},
   "source": [
    "**If you are in the `docker_lsdtt_pytools` docker container, you do not need to do any of this. \n",
    "The following is for executing this code in the google colab environment only.**\n",
    "\n",
    "If you are in the docker container you can skip to the **First get data** section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d95763d",
   "metadata": {},
   "source": [
    "## Get the example data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b3eb5e",
   "metadata": {},
   "source": [
    "We need to get the example files. There are 7 files\n",
    "\n",
    "* Two files that have atmopheric data that are used to caculate cosmogenic production rates\n",
    "* The DEM (a `bil` and a `hdr` file)\n",
    "* Three files that have parameters for the cosmogenic analyis. \n",
    "\n",
    "The first two files are the same for any cosmogenic analysis. \n",
    "If you are using `lsdtopotools` you should be quite familiar with DEMs and topogaphic data. \n",
    "So after we download the files we will look in detail at the parameter files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/CRNData/NCEP2.bin\", \"NCEP2.bin\")\n",
    "urllib.request.urlretrieve(\"https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/CRNData/NCEP_hgt.bin\", \"NCEP_hgt.bin\")\n",
    "urllib.request.urlretrieve(\"https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/CRNData/SanBern.bil\", \"SanBern.bil\")\n",
    "urllib.request.urlretrieve(\"https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/CRNData/SanBern.hdr\", \"SanBern.hdr\")\n",
    "urllib.request.urlretrieve(\"https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/CRNData/SanBern_SS_CRNData.csv\", \"SanBern_SS_CRNData.csv\")\n",
    "urllib.request.urlretrieve(\"https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/CRNData/SanBern_SS_CRNRasters.csv\", \"SanBern_SS_CRNRasters.csv\")\n",
    "urllib.request.urlretrieve(\"https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/CRNData/SanBern_SS.CRNParam\", \"SanBern_SS.CRNParam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aaa394",
   "metadata": {},
   "source": [
    "We can just look at the files to see if they are all here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118550ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls SanBern*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4742f",
   "metadata": {},
   "source": [
    "## CAIRN parameter files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb889a2b",
   "metadata": {},
   "source": [
    "Right, lets have a look at carin parameter files. We will use pandas to look at their contents.\n",
    "\n",
    "Any CAIRN run needs three files. Their filename will contain the prefix of the DEM (here `SanBern`) and then the three file extensions:\n",
    "\n",
    "* `_CRNData.csv`: The data containing information about the data from the samples.\n",
    "* `_CRNRasters.csv`: This contains data about the underlying rasters\n",
    "* `.CRNParam`: This has other parameters about the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls SanBern*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CRNData_df = pd.read_csv(\"SanBern_SS_CRNData.csv\")\n",
    "CRNData_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d0a2c",
   "metadata": {},
   "source": [
    "All the columns in this file are required. The `sample_name`, `sample_latitude`, and `sample_longitude` should be self explanatory, although `sample_name` is always read as a string (so you can put any combinations of letters and numbers here, but please no spaces!!), and the latitude and longitude are in decimal degrees. The `nuclide` can be `Be10`, `Al26`, `C14`, or `Ne21`. The `concentration` and `AMS_uncertainty` are both in atoms/g. The final column, `standardisation`, must come from a predifined list.\n",
    "\n",
    "The standardisations are:\n",
    "* For 10Be: \n",
    "\n",
    "`07KNSTD`,`KNSTD`,`NIST_Certified`,`LLNL31000`,`LLNL10000`,`LLNL3000`,`LLNL1000`,`LLNL300`,`NIST_30000`,`NIST_30200`,`NIST_30300`,`NIST_30600`,`NIST_27900`,`S555`,`S2007`,`BEST433`,`BEST433N`,`S555N`,`S2007N`\n",
    "* For 26Al:\n",
    "\n",
    "`KNSTD`,`ZAL94`,`SMAL11`,`0`,`ZAL94N`,`ASTER`,`Z92-0222`\n",
    "\n",
    "These standards are reported by the lab that processed your data. If the standard isn't recognised then the the KN standard will be applied (which just scales the measured concentration by 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db6527",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRNData_df = pd.read_csv(\"SanBern.CRNParam\")\n",
    "CRNData_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6742bb",
   "metadata": {},
   "source": [
    "## Running an analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead173a",
   "metadata": {},
   "source": [
    "First we need to import some modules from `lsdviztools`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsdviztools.lsdbasemaptools as bmt\n",
    "from lsdviztools.lsdplottingtools import lsdmap_gdalio as gio\n",
    "import lsdviztools.lsdmapwrappers as lsdmw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52a6fcc",
   "metadata": {},
   "source": [
    "Lets get a hillshade an look at some of the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d51aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT all the parameter values must be passed as strings. \n",
    "# So even if the parameter is a number it always needs to be in quotations\n",
    "lsdtt_parameters = {\"write_hillshade\" : \"true\"}\n",
    "r_prefix = \"SanBern\"\n",
    "w_prefix = \"SanBern\"\n",
    "lsdtt_drive = lsdmw.lsdtt_driver(read_prefix = r_prefix,\n",
    "                                 write_prefix= w_prefix,\n",
    "                                 read_path = \"./\",\n",
    "                                 write_path = \"./\",\n",
    "                                 parameter_dictionary=lsdtt_parameters)\n",
    "lsdtt_drive.print_parameters()\n",
    "lsdtt_drive.run_lsdtt_command_line_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b3b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "DataDirectory = \"./\"\n",
    "\n",
    "# Use the capture comment to get rid of all the text\n",
    "# But it will also not display an inline image\n",
    "# So you need to call the image from the next line of code           \n",
    "Base_file = r_prefix\n",
    "this_img = lsdmw.SimpleHillshade(DataDirectory,Base_file,cmap=\"gist_earth\", \n",
    "                                 save_fig=True, size_format=\"geomorphology\",dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20dbbb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image(filename=this_img, width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfaf459",
   "metadata": {},
   "source": [
    "We can also plot the points. This is a little annoying since the headers in the data file do not have `latitude` and `longitude`, which are required. A little bit of `pandas` will sort that out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f15292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(CRNData_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96addf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CRNData_df = pd.read_csv(\"SanBern_SS_CRNData.csv\")\n",
    "CRNData_df[\"latitude\"] =  CRNData_df[\" sample_latitude\"]\n",
    "CRNData_df[\"longitude\"] =  CRNData_df[\" sample_longitude\"]\n",
    "CRNData_df.to_csv(\"SanBern_SS_CRNData_latlong.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334eb8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot points the hillshade\n",
    "import lsdviztools.lsdmapwrappers as lsdmw\n",
    "%matplotlib inline\n",
    "Base_file = \"SanBern\"\n",
    "DataDirectory = \"./\"\n",
    "this_img = lsdmw.PrintPointsOverHillshade(DataDirectory,Base_file, column_for_plotting = \"concentration\", \n",
    "                                          points_fname = \"SanBern_SS_CRNData_latlong.csv\", \n",
    "                                          scale_points = False, manual_size =20,\n",
    "                                          cmap=\"jet\", save_fig=False, size_format=\"geomorphology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fef7a",
   "metadata": {},
   "source": [
    "## Check the cosmo data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38a286e",
   "metadata": {},
   "source": [
    "In this next step we check to see if the cosmo data is in the right place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba17303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT all the parameter values must be passed as strings. \n",
    "# So even if the parameter is a number it always needs to be in quotations\n",
    "lsdtt_parameters = {\"cosmo_parameter_prefix\" : \"SanBern\",\n",
    "                    \"check_cosmo_basins\" : \"true\"}\n",
    "r_prefix = \"SanBern\"\n",
    "w_prefix = \"SanBern\"\n",
    "lsdtt_drive = lsdmw.lsdtt_driver(command_line_tool = \"lsdtt-cosmo-tool\",\n",
    "                                 read_prefix = r_prefix,\n",
    "                                 write_prefix= w_prefix,\n",
    "                                 read_path = \"./\",\n",
    "                                 write_path = \"./\",\n",
    "                                 parameter_dictionary=lsdtt_parameters)\n",
    "lsdtt_drive.print_parameters()\n",
    "lsdtt_drive.run_lsdtt_command_line_tool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9b273",
   "metadata": {},
   "source": [
    "This gets the basins, which we can plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f88044",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "DataDirectory = \"./\"\n",
    "Base_file = \"SanBern\"\n",
    "basins_img = lsdmw.PrintBasins_Complex(DataDirectory,Base_file,cmap=\"gist_earth\", \n",
    "                             size_format=\"geomorphology\",dpi=600, save_fig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa701a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(basins_img)\n",
    "from IPython.display import display, Image\n",
    "display(Image(filename=basins_img, width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054a6ce",
   "metadata": {},
   "source": [
    "Now we are going to extract the erosion rates. This takes a little while since it automatically calculates topographic shielding, which is the most computationally expensive step. \n",
    "\n",
    "There is a quite good argument that topographic shielding is not required, but I've not implemented an automatic skip of this step yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa08c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT all the parameter values must be passed as strings. \n",
    "# So even if the parameter is a number it always needs to be in quotations\n",
    "lsdtt_parameters = {\"print_production_raster\" : \"true\",\n",
    "                    \"cosmo_parameter_prefix\" : \"SanBern\",\n",
    "                    \"calculate_erosion_rates\" : \"true\"}\n",
    "r_prefix = \"SanBern\"\n",
    "w_prefix = \"SanBern\"\n",
    "lsdtt_drive = lsdmw.lsdtt_driver(command_line_tool = \"lsdtt-cosmo-tool\",\n",
    "                                 read_prefix = r_prefix,\n",
    "                                 write_prefix= w_prefix,\n",
    "                                 read_path = \"./\",\n",
    "                                 write_path = \"./\",\n",
    "                                 parameter_dictionary=lsdtt_parameters)\n",
    "lsdtt_drive.print_parameters()\n",
    "lsdtt_drive.run_lsdtt_command_line_tool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708b9c5",
   "metadata": {},
   "source": [
    "The results are in a file with the extension `_CRNResults.csv`\n",
    "\n",
    "This file has 3 rows of text at the beginning so to load it you need to use the `skiprows` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34866b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRNResults_df = pd.read_csv(\"SanBern_CRNResults.csv\",skiprows=3)\n",
    "CRNResults_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5181b2e6",
   "metadata": {},
   "source": [
    "If we want to plot this we need to get rid of the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c062cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRNResults_df.to_csv(\"SanBern_CRNResults_dropheader.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57339b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot points the hillshade\n",
    "import lsdviztools.lsdmapwrappers as lsdmw\n",
    "%matplotlib inline\n",
    "Base_file = \"SanBern\"\n",
    "DataDirectory = \"./\"\n",
    "this_img = lsdmw.PrintPointsOverHillshade(DataDirectory,Base_file, column_for_plotting = \"erate_mmperkyr_rho2650\", \n",
    "                                          points_fname = \"SanBern_CRNResults_dropheader.csv\", \n",
    "                                          scale_points = False, manual_size =30,\n",
    "                                          cmap=\"jet\", save_fig=False, size_format=\"geomorphology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a140e7",
   "metadata": {},
   "source": [
    "## Get points using the updated CRN erosion rate routine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5ef1e",
   "metadata": {},
   "source": [
    "We have developed an erosion rate calculator with a simpler interface. \n",
    "\n",
    "You just need a file with latitude, longitude and concentrations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7454c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT all the parameter values must be passed as strings. \n",
    "# So even if the parameter is a number it always needs to be in quotations\n",
    "lsdtt_parameters = {\"points_filename\" : \"SanBern_SS_CRNData_latlong.csv\",\n",
    "                    \"nuclide_for_prediction\" : \"Be10\",\n",
    "                    \"concentration_column_name\" : \"concentration\",\n",
    "                    \"calculate_erosion_rates_new\" : \"true\"}\n",
    "r_prefix = \"SanBern\"\n",
    "w_prefix = \"SanBern\"\n",
    "lsdtt_drive = lsdmw.lsdtt_driver(command_line_tool = \"lsdtt-cosmo-tool\",\n",
    "                                 read_prefix = r_prefix,\n",
    "                                 write_prefix= w_prefix,\n",
    "                                 read_path = \"./\",\n",
    "                                 write_path = \"./\",\n",
    "                                 parameter_dictionary=lsdtt_parameters)\n",
    "lsdtt_drive.print_parameters()\n",
    "lsdtt_drive.run_lsdtt_command_line_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b6aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ecfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "New_results_df = pd.read_csv(\"SanBern_CN_ERATE.csv\")\n",
    "New_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb16b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lets see how close this came to the CAIRN method. This doesn't have the topographic shielding component, mainly be=cause of theoretical work by DiBiase that showed topographic shielding is offset by greater surface exposure in sloping terrain (https://esurf.copernicus.org/articles/6/923/2018/esurf-6-923-2018.html) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
