{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LSDtopotools/lsdtt_notebooks/blob/master/lsdtopotools/basic_examples/getting_a_channel_profile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d333d55e",
      "metadata": {
        "id": "d333d55e"
      },
      "source": [
        "# Getting a channel profile"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed93a83c",
      "metadata": {
        "id": "ed93a83c"
      },
      "source": [
        "Last updated by Simon M Mudd on 08/05/2023"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faf26884",
      "metadata": {
        "id": "faf26884"
      },
      "source": [
        "You just want to get a channel profile! Or maybe you have some data and want to get information about the channel where you collected the data. \n",
        "\n",
        "This takes you through downloading the data and selecting a channel. \n",
        "\n",
        "You can either select a basin or a starting point. This shows you both ways to do it. \n",
        "\n",
        "This notebook will also show you how to take some field sites with geospatial loactions and map channel information such as elevation and drainage area onto those points. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b27be8f",
      "metadata": {
        "id": "4b27be8f"
      },
      "source": [
        "## If you are on colab"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "994da2f2",
      "metadata": {
        "id": "994da2f2"
      },
      "source": [
        "**If you are in the `docker_lsdtt_pytools` docker container, you do not need to do any of this. \n",
        "The following is for executing this code in the google colab environment only.**\n",
        "\n",
        "If you are in the docker container you can skip to the **First get data** section. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "341fea0a",
      "metadata": {},
      "source": [
        "First we install `lsdtopotools`. The first line downloads the package and the second installs it. The `/dev/null` stuff is just to stop the notebook printing a bunch of text to screen.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61a434c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://pkgs.geos.ed.ac.uk/geos-jammy/pool/world/l/lsdtopotools2/lsdtopotools2_0.9-1geos~22.04.1_amd64.deb  &> /dev/null\n",
        "!apt install ./lsdtopotools2_0.9-1geos~22.04.1_amd64.deb  &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e7c389a",
      "metadata": {},
      "source": [
        "The next line tests to see if it worked. If you get some output asking for a parameter file then `lsdtopotools` is installed. This notebook was tested on version 0.9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb3a7213",
      "metadata": {},
      "outputs": [],
      "source": [
        "!lsdtt-basic-metrics -v"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a7461d5",
      "metadata": {},
      "source": [
        "Now we install `lsdviztools`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "292190a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install lsdviztools  &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2146b6d9",
      "metadata": {
        "id": "2146b6d9"
      },
      "source": [
        "## First get data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324a327a",
      "metadata": {
        "id": "324a327a"
      },
      "source": [
        "We need to get some data to download. \n",
        "\n",
        "We are going to get some data from the centre of Lesotho, in some small catchements draining to the Orange River. \n",
        "\n",
        "We are going to download data using the opentopography scraper that is included with `lsdviztools`. You will need to get an opentopography.org account and copy in your API key. \n",
        "\n",
        "You can sign up to an opentopography.org account here: https://portal.opentopography.org/myopentopo "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d62c76c",
      "metadata": {
        "id": "5d62c76c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import lsdviztools.lsdbasemaptools as bmt\n",
        "from lsdviztools.lsdplottingtools import lsdmap_gdalio as gio\n",
        "\n",
        "# YOU NEED TO PUT YOUR API KEY IN A FILE\n",
        "your_OT_api_key_file = \"my_OT_api_key.txt\"\n",
        "\n",
        "with open(your_OT_api_key_file, 'r') as file:\n",
        "    print(\"I am reading you OT API key from the file \"+your_OT_api_key_file)\n",
        "    api_key = file.read().rstrip()\n",
        "    print(\"Your api key starts with: \"+api_key[0:4])\n",
        "\n",
        "Dataset_prefix = \"Lesotho\"\n",
        "source_name = \"COP30\"\n",
        "\n",
        "Xian_DEM = bmt.ot_scraper(source = source_name,\n",
        "                        lower_left_coordinates = [-29.986795303183285, 28.210294055430822], \n",
        "                        upper_right_coordinates = [-29.546820300795922, 28.636351905601636],\n",
        "                        prefix = Dataset_prefix, \n",
        "                        api_key_file = your_OT_api_key_file)\n",
        "Xian_DEM.print_parameters()\n",
        "Xian_DEM.download_pythonic()\n",
        "DataDirectory = \"./\"\n",
        "Fname = Dataset_prefix+\"_\"+source_name+\".tif\"\n",
        "gio.convert4lsdtt(DataDirectory,Fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4989ccf",
      "metadata": {
        "id": "b4989ccf"
      },
      "source": [
        "Let's check to see what the filenames we generated are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "454a1496",
      "metadata": {
        "id": "454a1496"
      },
      "outputs": [],
      "source": [
        "!ls Lesotho*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32535c8d",
      "metadata": {
        "id": "32535c8d"
      },
      "source": [
        "## Look at the hillshade"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82861e28",
      "metadata": {
        "id": "82861e28"
      },
      "source": [
        "Right, lets see what this place looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4429922",
      "metadata": {
        "id": "a4429922"
      },
      "outputs": [],
      "source": [
        "import lsdviztools.lsdmapwrappers as lsdmw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c6d4f1",
      "metadata": {
        "id": "52c6d4f1"
      },
      "outputs": [],
      "source": [
        "lsdtt_parameters = {\"write_hillshade\" : \"true\"}\n",
        "\n",
        "Dataset_prefix = \"Lesotho\"\n",
        "source_name = \"COP30\"\n",
        "\n",
        "r_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "w_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "lsdtt_drive = lsdmw.lsdtt_driver(read_prefix = r_prefix,\n",
        "                                 write_prefix= w_prefix,\n",
        "                                 read_path = \"./\",\n",
        "                                 write_path = \"./\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()\n",
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbdbb352",
      "metadata": {
        "id": "cbdbb352"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "Base_file = r_prefix\n",
        "DataDirectory = \"./\"\n",
        "this_img = lsdmw.SimpleHillshade(DataDirectory,Base_file,cmap=\"gist_earth\", save_fig=False, size_format=\"geomorphology\",dpi=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0507f7af",
      "metadata": {
        "id": "0507f7af"
      },
      "source": [
        "## Get a channel by basin"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60097467",
      "metadata": {
        "id": "60097467"
      },
      "source": [
        "Lets get a channel by basin. I will make a pandas dataframe with the outlet location (I get this from google maps, just right click where you want it and copy the lat-long) and then create a csv file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ab993ad",
      "metadata": {
        "id": "1ab993ad",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "data = [ [-29.74268168812215, 28.359698313955146]]\n",
        "\n",
        "# Create the pandas DataFrame\n",
        "df = pd.DataFrame(data, columns = ['latitude', 'longitude'])\n",
        "\n",
        "df.to_csv(\"basin_outlets.csv\",index=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7b610c3",
      "metadata": {
        "id": "b7b610c3"
      },
      "source": [
        "From this outlet we will extract the basin and also get a channel profile. \n",
        "There are various options but the one that includes channel profile alongside drainage area and the chi coordinate (see https://onlinelibrary.wiley.com/doi/abs/10.1002/esp.3302) is `print_chi_data_maps`:\n",
        "\n",
        "**WARNING** This will not accept basins that touch the edge of the DEM. So you need to put your point a bit upstream of a tributary junction if it joins with a bigger basin that drains to the edge. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93241ad1",
      "metadata": {
        "id": "93241ad1"
      },
      "outputs": [],
      "source": [
        "## Get the basins and the channel profile\n",
        "lsdtt_parameters = {\"print_basin_raster\" : \"true\",\n",
        "                    \"print_chi_data_maps\" : \"true\",\n",
        "                    \"get_basins_from_outlets\" : \"true\",\n",
        "                    \"basin_outlet_csv\" : \"basin_outlets.csv\"}\n",
        "r_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "w_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "lsdtt_drive = lsdmw.lsdtt_driver(command_line_tool = \"lsdtt-chi-mapping\", \n",
        "                                 read_prefix = r_prefix,\n",
        "                                 write_prefix= w_prefix,\n",
        "                                 read_path = \"./\",\n",
        "                                 write_path = \"./\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()\n",
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aN93y6dQxBe6",
      "metadata": {
        "id": "aN93y6dQxBe6"
      },
      "outputs": [],
      "source": [
        "!lsdtt-chi-mapping Test_01.driver"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b4a7f54",
      "metadata": {
        "id": "4b4a7f54"
      },
      "source": [
        "Okay, lets have a look at the basin we got:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50733c9a",
      "metadata": {
        "id": "50733c9a"
      },
      "outputs": [],
      "source": [
        "%%capture             \n",
        "Base_file = r_prefix\n",
        "basins_img = lsdmw.PrintBasins_Complex(DataDirectory,Base_file,cmap=\"gist_earth\", \n",
        "                             size_format=\"geomorphology\",dpi=600, save_fig = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c3ac3c",
      "metadata": {
        "id": "c0c3ac3c"
      },
      "outputs": [],
      "source": [
        "print(basins_img)\n",
        "from IPython.display import display, Image\n",
        "display(Image(filename=basins_img, width=800))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44cfc376",
      "metadata": {
        "id": "44cfc376"
      },
      "source": [
        "Okay, now the channel profile is in a csv file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b5c7006",
      "metadata": {
        "id": "9b5c7006"
      },
      "outputs": [],
      "source": [
        "!ls Lesotho*csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b2ae066",
      "metadata": {
        "id": "3b2ae066"
      },
      "source": [
        "## Plot channels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bbc9ce6",
      "metadata": {
        "id": "6bbc9ce6"
      },
      "source": [
        "We can plot the channels using the command line script from `lsdviztools`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c3dd816",
      "metadata": {
        "id": "2c3dd816",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "!lsdtt_plotbasicrasters -dir ./ -fname Lesotho_COP30_UTM -PCh true"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ce83517",
      "metadata": {
        "id": "3ce83517"
      },
      "source": [
        "This puts the plot in a subdirectory called `raster_plots`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f171453",
      "metadata": {
        "id": "1f171453"
      },
      "outputs": [],
      "source": [
        "!ls raster_plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd866071",
      "metadata": {
        "id": "fd866071"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Image\n",
        "display(Image(filename=\"raster_plots/Lesotho_COP30_UTM_ChElevation_chi_channels_and_basins.png\", width=800))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "069fd058",
      "metadata": {
        "id": "069fd058"
      },
      "source": [
        "We can also do that natively here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84496931",
      "metadata": {
        "id": "84496931"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "this_curv_img = lsdmw.PrintChannelsAndBasins(DataDirectory,Base_file,\n",
        "                                       add_basin_labels = True, cmap = \"jet\", \n",
        "                                       size_format = \"ESURF\", fig_format = \"png\", \n",
        "                                       dpi = 300, save_fig = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3766ea5",
      "metadata": {
        "id": "c3766ea5"
      },
      "source": [
        "Or we could load the data as a pandas dataframe and plot the profile:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "392811bd",
      "metadata": {
        "id": "392811bd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Lesotho_COP30_UTM_chi_data_map.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c0e719",
      "metadata": {
        "id": "b4c0e719"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(df.flow_distance,df.elevation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95e7e0a6",
      "metadata": {
        "id": "95e7e0a6"
      },
      "outputs": [],
      "source": [
        "plt.scatter(df.chi,df.elevation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da1f231f",
      "metadata": {
        "id": "da1f231f"
      },
      "source": [
        "## What if I don't want a basin but instead want to select a source?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dc3f5f7",
      "metadata": {
        "id": "8dc3f5f7"
      },
      "source": [
        "In some cases your channel is cut off by the edge of the DEM but you still want a profile. The basin selection tools look to calculate drainage area and this will be incorrect in an incomplete basin. But you can select a channel by source, allowing you to just get elevation downstream. We need to tell `lsdtopotools` where the source point is, and we do that with a csv file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfcdcddd",
      "metadata": {
        "id": "bfcdcddd"
      },
      "outputs": [],
      "source": [
        "# Import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "data = [ [-29.574418486660242, 28.262105221820292]]\n",
        "\n",
        "# Create the pandas DataFrame\n",
        "df = pd.DataFrame(data, columns = ['latitude', 'longitude'])\n",
        "\n",
        "df.to_csv(\"channel_source.csv\",index=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea90f2e8",
      "metadata": {
        "id": "ea90f2e8"
      },
      "outputs": [],
      "source": [
        "lsdtt_parameters = {\"extract_single_channel\" : \"true\", \n",
        "                    \"channel_source_fname\" : \"channel_source.csv\"}\n",
        "\n",
        "Dataset_prefix = \"Lesotho\"\n",
        "source_name = \"COP30\"\n",
        "\n",
        "r_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "w_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "lsdtt_drive = lsdmw.lsdtt_driver(read_prefix = r_prefix,\n",
        "                                 write_prefix= w_prefix,\n",
        "                                 read_path = \"./\",\n",
        "                                 write_path = \"./\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()\n",
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ebc807c",
      "metadata": {
        "id": "5ebc807c"
      },
      "source": [
        "The file from this goes into something called `single_channel_nodes.csv`. We can load it into a pandas dataframe and have a look at it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4814be7f",
      "metadata": {
        "id": "4814be7f"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"single_channel_nodes.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4243ba59",
      "metadata": {
        "id": "4243ba59"
      },
      "source": [
        "To plot columns from a data frame you need to know the column headers. Sometimes these have white space. So if you use the `list` function you can get the exact headers in order to plot the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1395185f",
      "metadata": {
        "id": "1395185f"
      },
      "outputs": [],
      "source": [
        "list(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "654ca4f5",
      "metadata": {
        "id": "654ca4f5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.scatter(df[\"flow distance(m)\"],df[\"elevation(m)\"])\n",
        "plt.scatter(df[\" flow distance(m)\"],df[\" elevation(m)\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eHiIQjxI4S7I",
      "metadata": {
        "id": "eHiIQjxI4S7I"
      },
      "source": [
        "## Another example getting channel characteristics from specific sites. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4_JWAlUL4UqL",
      "metadata": {
        "id": "4_JWAlUL4UqL"
      },
      "source": [
        "Here we will download data from another place, this time in Scotland. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B1Bu1JL65vQM",
      "metadata": {
        "id": "B1Bu1JL65vQM"
      },
      "outputs": [],
      "source": [
        "lower_left_coord = [54.725951808268405, -4.3164633347178825]\n",
        "upper_right_coord = [55.70870947547077, -3.553609989341891]\n",
        "\n",
        "import lsdviztools.lsdbasemaptools as bmt\n",
        "from lsdviztools.lsdplottingtools import lsdmap_gdalio as gio\n",
        "\n",
        "# YOU NEED TO PUT YOUR API KEY IN A FILE\n",
        "your_OT_api_key_file = \"my_OT_api_key.txt\"\n",
        "\n",
        "with open(your_OT_api_key_file, 'r') as file:\n",
        "    print(\"I am reading you OT API key from the file \"+your_OT_api_key_file)\n",
        "    api_key = file.read().rstrip()\n",
        "    print(\"Your api key starts with: \"+api_key[0:4])\n",
        "\n",
        "Dataset_prefix = \"Nith\"\n",
        "source_name = \"COP30\"\n",
        "\n",
        "Nith_DEM = bmt.ot_scraper(source = source_name,\n",
        "                        lower_left_coordinates = lower_left_coord, \n",
        "                        upper_right_coordinates = upper_right_coord,\n",
        "                        prefix = Dataset_prefix, \n",
        "                        api_key_file = your_OT_api_key_file)\n",
        "Nith_DEM.print_parameters()\n",
        "Nith_DEM.download_pythonic()\n",
        "DataDirectory = \"./\"\n",
        "Fname = Dataset_prefix+\"_\"+source_name+\".tif\"\n",
        "gio.convert4lsdtt(DataDirectory,Fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bbrzgh-HpRz",
      "metadata": {
        "id": "2bbrzgh-HpRz"
      },
      "source": [
        "We will extract a single basin, which is the outlet of the River Nith."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MVNeM9eRHjkz",
      "metadata": {
        "id": "MVNeM9eRHjkz"
      },
      "outputs": [],
      "source": [
        "# Import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "data = [ [55.03554646506262, -3.60572251060801]]\n",
        "\n",
        "# Create the pandas DataFrame\n",
        "df = pd.DataFrame(data, columns = ['latitude', 'longitude'])\n",
        "\n",
        "df.to_csv(\"basin_outlets.csv\",index=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mvPVNhUjsa9i",
      "metadata": {
        "id": "mvPVNhUjsa9i"
      },
      "source": [
        "Now we will get the basin raster, we will also print the hillshade, and get the channel data using a keyword `print_chi_data_maps`. I am also going to control how many tributaries I get. I set the threshold number of pixels I need draining into a given pixel to form a channel. Here I use 5000 pixels. This is a 30 m DEM, so each pixel is 900 m$^2$, so the channel sources will be pixels with 4.5 million squre metres or 4.5 square kilometres in drainage area. I set this with the keyword `\"threshold_contributing_pixels\" : \"5000\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vGMIA_sqsLlW",
      "metadata": {
        "id": "vGMIA_sqsLlW"
      },
      "outputs": [],
      "source": [
        "import lsdviztools.lsdmapwrappers as lsdmw\n",
        "\n",
        "## Get the basins and the channel profile\n",
        "lsdtt_parameters = {\"print_basin_raster\" : \"true\",\n",
        "                    \"write_hillshade\" : \"true\",\n",
        "                    \"print_chi_data_maps\" : \"true\",\n",
        "                    \"get_basins_from_outlets\" : \"true\",\n",
        "                    \"threshold_contributing_pixels\" : \"5000\",\n",
        "                    \"basin_outlet_csv\" : \"basin_outlets.csv\",\n",
        "                    \"extend_channel_to_node_before_receiver_junction\" : \"false\"}\n",
        "r_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "w_prefix = Dataset_prefix+\"_\"+source_name +\"_UTM\"\n",
        "lsdtt_drive = lsdmw.lsdtt_driver(command_line_tool = \"lsdtt-basic-metrics\", \n",
        "                                 read_prefix = r_prefix,\n",
        "                                 write_prefix= w_prefix,\n",
        "                                 read_path = \"./\",\n",
        "                                 write_path = \"./\",\n",
        "                                 parameter_dictionary=lsdtt_parameters)\n",
        "lsdtt_drive.print_parameters()\n",
        "lsdtt_drive.run_lsdtt_command_line_tool()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "miloOYD3uHsc",
      "metadata": {
        "id": "miloOYD3uHsc"
      },
      "source": [
        "Okay, lets look at the river we extracted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IjknGnhW9NTT",
      "metadata": {
        "id": "IjknGnhW9NTT"
      },
      "outputs": [],
      "source": [
        "%%capture             \n",
        "Base_file = r_prefix\n",
        "DataDirectory = \"./\"\n",
        "basins_img = lsdmw.PrintBasins_Complex(DataDirectory,Base_file,cmap=\"gist_earth\", \n",
        "                             size_format=\"geomorphology\",dpi=600, save_fig = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u36afKF-4RkQ",
      "metadata": {
        "id": "u36afKF-4RkQ"
      },
      "outputs": [],
      "source": [
        "print(basins_img)\n",
        "from IPython.display import display, Image\n",
        "display(Image(filename=basins_img, width=800))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xHoVit-a5Vdj",
      "metadata": {
        "id": "xHoVit-a5Vdj"
      },
      "source": [
        "We can use some plotting tools to see where this is"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CK2yqCNt0J0X",
      "metadata": {
        "id": "CK2yqCNt0J0X"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "Base_file = r_prefix\n",
        "DataDirectory = \"./\"\n",
        "this_curv_img = lsdmw.PrintChannelsAndBasins(DataDirectory,Base_file,\n",
        "                                       add_basin_labels = True, cmap = \"jet\", \n",
        "                                       size_format = \"ESURF\", fig_format = \"png\", \n",
        "                                       dpi = 300, save_fig = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "njcC4yoS0uFx",
      "metadata": {
        "id": "njcC4yoS0uFx"
      },
      "source": [
        "Now say you had some sites and you wanted to find the drainage characteristics of those sites. I'm going to make the sites. The file, at minimum, need a `latitude` and `longitude` column. Make sure those are lower case:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R0IC_WPy0Qvc",
      "metadata": {
        "id": "R0IC_WPy0Qvc"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "data = [\n",
        "    [\"site\",\"Easting\",\"Northing\",\"longitude\",\"latitude\"],\n",
        "    [\"Scar0001\",275911,602987,-3.956336,55.305283],\n",
        "    [\"Aftn0001\",263158,608025,-4.159543,55.347139],\n",
        "    [\"Camp0001\",287165,594055,-3.775567,55.227772],\n",
        "    [\"Craw0001\",282305,617799,-3.86191,55.439879],\n",
        "    [\"Dlwt0001\",271106,595647,-4.028614,55.238134],\n",
        "    [\"Menn0001\",283787,609803,-3.835166,55.368422],\n",
        "    [\"Nith010\",291286,586310,-3.707828,55.159133],\n",
        "    [\"Nith053\",259689,613818,-4.217112,55.398175],\n",
        "    [\"Nith027\",272142,612363,-4.019952,55.388515],\n",
        "    [\"Nith0001\",253724,609294,-4.30885,55.355815]\n",
        "]\n",
        "\n",
        "filename = \"nith_sites.csv\"\n",
        "\n",
        "with open(filename, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(data)\n",
        "\n",
        "print(f\"Data has been successfully written to {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZBkhkzK-14xO",
      "metadata": {
        "id": "ZBkhkzK-14xO"
      },
      "outputs": [],
      "source": [
        "!cat nith_sites.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yCOmerUe2LOr",
      "metadata": {
        "id": "yCOmerUe2LOr"
      },
      "source": [
        "Now we need to import some stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7oV41PzS17OD",
      "metadata": {
        "id": "7oV41PzS17OD"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from scipy.spatial import cKDTree\n",
        "from shapely.geometry import Point"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iBzjaPCw2SwD",
      "metadata": {
        "id": "iBzjaPCw2SwD"
      },
      "source": [
        "We have two datasets. One is the channel data and the other is the site locations. This second dataset could be any set of points.\n",
        "\n",
        "We will, in the next step, merge these datasets based on the nearest neighbour to one of the set of points (i.e., mapping channel data to the nearest site).\n",
        "\n",
        "For this to work, the two datasets must be in the same coordinate reference system. For this example it is not really a problem because both datasets have coordinates in a global reference frame with the code EPSG:4326. In the example below, we use .crs to define the coordinate reference system. \n",
        "\n",
        "However, sometimes you might have a data set with another cooridante system (fore example British National Grid, which is EPSG:27700, so you would need to change the corresponding EPSG code. You can look up the EPSG code for a coordinate system with a google search. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XB737H552PAz",
      "metadata": {
        "id": "XB737H552PAz"
      },
      "outputs": [],
      "source": [
        "# Load the channel data\n",
        "dfA = pd.read_csv(\"Nith_COP30_UTM_chi_data_map.csv\")\n",
        "# Convert to a geopandas dataframe\n",
        "gdfA = gpd.GeoDataFrame(\n",
        "    dfA, geometry=gpd.points_from_xy(dfA.longitude, dfA.latitude))\n",
        "# We have to tell the geopandas data what geographic system we are in by using something called an EPSG code. \n",
        "# All major geographic projection and transformation system have this code. \n",
        "gdfA.crs = \"EPSG:4326\" \n",
        "\n",
        "\n",
        "# Load the width data\n",
        "dfB = pd.read_csv(\"nith_sites.csv\")\n",
        "gdfB = gpd.GeoDataFrame(\n",
        "    dfB, geometry=gpd.points_from_xy(dfB.longitude, dfB.latitude))\n",
        "# We have to tell the geopandas data what geographic system we are in by using something called an EPSG code. \n",
        "# All major geographic projection and transformation system have this code. \n",
        "gdfB.crs = \"EPSG:4326\" \n",
        "\n",
        "# IMPORTANT: we convert one of the datasets to the coordinate reference system of the other\n",
        "gdfC = gdfB.to_crs(4326)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bkZBjRNC3z_N",
      "metadata": {
        "id": "bkZBjRNC3z_N"
      },
      "source": [
        "I now need to add a function for combining datasets. **You don't need to change anything in this function.** The first dataframe keeps its data elements and adds properties from the nearest neighbour that are closest to the points in the first dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eHz9vpmn37Xe",
      "metadata": {
        "id": "eHz9vpmn37Xe"
      },
      "outputs": [],
      "source": [
        "def ckdnearest(gdA, gdB):\n",
        "\n",
        "    nA = np.array(list(gdA.geometry.apply(lambda x: (x.x, x.y))))\n",
        "    nB = np.array(list(gdB.geometry.apply(lambda x: (x.x, x.y))))\n",
        "    btree = cKDTree(nB)\n",
        "    dist, idx = btree.query(nA, k=1)\n",
        "    gdB_nearest = gdB.iloc[idx].drop(columns=\"geometry\").reset_index(drop=True)\n",
        "    gdf = pd.concat(\n",
        "        [\n",
        "            gdA.reset_index(drop=True),\n",
        "            gdB_nearest,\n",
        "            pd.Series(dist, name='dist')\n",
        "        ], \n",
        "        axis=1)\n",
        "\n",
        "    return gdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mik7_Rzu3-nG",
      "metadata": {
        "id": "mik7_Rzu3-nG"
      },
      "source": [
        "Now we merge the two files. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MFsNj1tK39Tv",
      "metadata": {
        "id": "MFsNj1tK39Tv"
      },
      "outputs": [],
      "source": [
        "new_gdp = ckdnearest(gdfC, gdfA)\n",
        "new_gdp.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NOOIFQwQ4J3v",
      "metadata": {
        "id": "NOOIFQwQ4J3v"
      },
      "source": [
        "Super! Now we can print this new dataset to a file using the .to_csv function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-UZICSmx4CIW",
      "metadata": {
        "id": "-UZICSmx4CIW"
      },
      "outputs": [],
      "source": [
        "new_gdp.to_csv(\"updated_nith_site_infomations.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
